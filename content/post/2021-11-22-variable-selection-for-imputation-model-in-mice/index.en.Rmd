---
title: Variable selection for imputation model in {mice}
author: tengku-hanis
date: '2021-11-22'
slug: variable-selection-for-imputation-model-in-mice
categories:
  - R
  - applied statistics
tags:
  - missing data
subtitle: ''
summary: ''
authors: []
lastmod: '2021-11-22T07:55:40+08:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

## Some note

I have written a [short post](https://tengkuhanis.netlify.app/post/a-short-note-on-multiple-imputation/) about missing data and multiple imputation in `mice` package previously. This post will add to that previous post.

## Imputation model

Imputation model is the model that we use for our imputation approach. There is another term which is complete-data model. This is a model that we want to fit after we impute the missing values (i.e; the complete-data model is the final model).

Generally, we need to include as many relevant variables into the imputation model. However, this general advise may not be very efficient as we may have multicollinearity and computational issue if we include too many predictors. As a rule of thumb, the number of included variables should be no more than 15-20. [van Buuren *et al*](https://www.jstatsoft.org/article/view/v045i03)*.* [(2011)](https://www.jstatsoft.org/article/view/v045i03) mentioned that increased in explained variance in linear regression is negligible after 15 variables are included.

There are 4 steps suggested by [van Buuren *et al.* (1999)](https://stefvanbuuren.name/publications/Flexible%20multivariate%20-%20TNO99054%201999.pdf) for variable selection in the case of big data:

1.  Include all variables that appear in the complete-data model (final model).

    -   This may include this interaction terms as well (passive imputation can be used for this in `mice` package).

2.  Include variable that have influence on the occurrence of the missing data.

    -   This can be assessed by a correlation matrix between NAs variables and non-NAs variables.

3.  Include variable that explain a considerable amount of variance.

    -   This can be crudely assessed by a correlation matrix between NAs variables and non-NAs variables.

4.  Remove variable that have too many missing values within the subgroup of incomplete cases.

    -   This can be assessed by a proportion of usable cases (PUC) - how many cases with missing data in the certain variable have an observed values on the predictor variables.

All these steps should be done on the key variables only. There is another more efficient yet laborious approach suggested by [Oudshoorn *et al.* (1999)](https://stefvanbuuren.name/publications/Flexible%20multiple%20-%20TNO99045%201999.pdf), which take into account important predictor of predictors. We are going focus on the four steps above, and not cover the latter suggested approach in this post.

## R codes

These are the required packages.

```{r}
library(mice)
library(corrplot)
```

Our data.

```{r}
summary(airquality)
```

We have 2 variables; Ozone and Solar.R with missing values or NAs. We can further explore the pattern of missing variable.

```{r}
md.pattern(airquality)
```

There are 2 rows with NAs in Ozone and Solar.R, 35 rows with NAs only in Ozone, and 5 rows with NAs only in Solar.R. Next, we can check the correlation.

```{r}
cor(airquality, use = "pairwise.complete.obs") |>
  corrplot(method = "number", type = "upper")
```

The correlations of Ozone-Temp and Ozone-Wind are the highest. Now, let's do a correlation between the NAs variable and non-NAs variable.

```{r}
cor(y = airquality, x = !is.na(airquality), use = "pairwise.complete.obs") |>
  round(digits = 2)
```

We can ignore the warnings and the NAs as only Ozone and Solar.R have a missing values. So, the highest correlation is 0.26 between Month-Ozone - correlation between Month values with Ozone-related NAs and Month values with non-Ozone-related NAs. The column variable in the correlation matrix is the indicators of NAs and the row variables is the variable with observed values.

Lastly we can calculate 'manually' the PUC (proportion of usable cases). `md.pairs()` here calculate the number of observation per variable pair.

```{r}
var_pair <- md.pairs(airquality)
round(var_pair$mr / (var_pair$mr + var_pair$mm), digits = 3)
```

Low value of PUC indicate there is a little information on the predictor to impute the target NAs variable. NaN is shown as the variables have no missing values. The row variable are the target variables to be imputed, and the column variables are the predictors in imputation model. We can see that to impute Solar.R (on the row) Ozone has a little less information (0.714) compare to Wind, Temp, and Day. The diagonal elements will always be 0 or NaN. So, from here we can drop predictors with say, 0 PUC as they contain no information to help impute the target NAs variable.

Actually, we have a nice function from `mice` that can do what we 'manually' did just now.

```{r}
quickpred(airquality)

```

Again, the column variables are the predictors, and the row variable is the target NAs variables. The above matrix is known as predictor matrix, which going to be used in the imputation model. 1 denote a variable included as predictors and 0 vice versa. The two main arguments in `quickpred()` are:

-   mincor - if any of the absolute values in the two correlation matrix that we did earlier above 0.1 (default), the predictors will be included in the predictor matrix.

-   minpuc - the default values for PUC is 0, so the predictors are retained even if they have no information to help imputation model.

Notice that, variable Day is excluded from the predictors of Ozone. The correlation values are 0 and -0.05 from the first and second correlation matrices, respectively which do not exceed default setting of 0.1. That's why, variable Day is excluded. Also, we can observe a similar situation for variable Wind , which is excluded from the predictors of Solar.R (the correlation coefficients are -0.60 and 0.06). The negative (-) sign does not matter as we actually evaluate the absolute values.

As we can see we can change these two arguments as we see fit to do a variable selection for imputation model. Once we finalise our variable selection for imputation model. We can do the multiple imputation using `mice()`.

```{r}
# Finalised variable selection
var_sel <- quickpred(airquality)
var_sel

# Impute
imp <- mice(airquality, m = 5, predictorMatrix = var_sel, printFlag = F)
imp
```

Notice that `mice()` uses the predictor matrix that we provide.

References:

1.  <https://www.jstatsoft.org/article/view/v045i03> - paper written byStaf van Buuren (a bit outdated in terms of codes, but runnable)

2.  <https://stefvanbuuren.name/fimd/> - online book written by Stef van Buuren (See chapter 6.3.2 and 9.1.6)